---
layout: post
title: 파이썬을 활용한 애플 주가수익률 예측 분석 - (3). 교차 검증 및 모델 선택
date: 2023-05-02
categories: ["3. 튜토리얼", "금융 분석 프로그래밍 응용"]

---


본 시리즈는 주가 데이터의 **자기 상관(Auto-Correlation) 특성을 억제**하고, **동시간대 연관 자산(Cross-Sectional) 수익률 및 지연 수익률을 통한 미래 주가 수익률 예측**하는 내용을 담고 있다. 본 장에서는 [(1). 데이터 확인 및 예측 안정성 확보](https://songseungwon.tistory.com/141), [(2). 변수간 상관분석 및 예측변수 정상성 검정](https://songseungwon.tistory.com/142)에 이어 예측 모델을 구현하는 세 번째 실습을 진행한다.

실습은 회귀(Regression) 예측을 위한 다양한 모델들을 일괄 구현한 다음, 교차검증(K-Fold Cross Validation)을 수행함으로써 각각의 성능을 비교 분석하는 방식으로 진행된다.

**Step 1. Train-Test Dataset Split**
------------------------------------

![](/assets/images/posts/143-0.webp)

데이터는 [이전 장](https://songseungwon.tistory.com/142)에서 구축한 df\_Xy를 사용한다.

![](/assets/images/posts/143-1.webp)

예측 변수는 y, 애플 주가(AAPL)의 미래수익률이고 설명 변수는 X, 애플 주가의 지연(과거 5일, 20일, 60일 대비) 수익률과 연관 자산의 현재 수익률이 되겠다. sklearn.model\_selection의 train\_test\_split을 사용하면 간단히 분리할 수 있는데, 여기서는 shuffle 같은 무작위 변환 작업을 하지 않기 때문에 굳이 라이브러리를 사용하지 않고 판다스 iloc 함수를 통해 즉시 8:2로 슬라이싱해주는 편이 더 좋겠다.

**Step 2. Model Selection**
---------------------------

회귀 모형은 다양한 방식으로 구현할 수 있다. 단순 회귀모형뿐만 아니라 제약(규제)을 받는 회귀, 거리 기반 회귀, 트리 구조의 회귀, 그리고 앙상블과 신경망으로 더 복잡하게 구현한 회귀 모형까지 그 종류는 매우 다양하다. 이 중 어떤 것이 현재의 데이터셋에 가장 예측력이 우수한지, 어떤 것이 가장 Robust(현실에서의 이상치, 특이값에 대해 영향을 덜 받는)한 지 판단하고자 위해 교차검증(Cross-Validation)을 수행해 볼 수 있다.

### **2-1. Modeling**

![](/assets/images/posts/143-2.webp)

교차검증을 수행하기 전에 먼저 리스트를 하나 만들고 비교 분석할 모델을 모두 담아준다. 이 때, 이후 시각화를 위해 (이름, 모델) 쌍의 튜플 형식으로 구조화하자. 참고로 모델 패키지는 [1장](https://songseungwon.tistory.com/141)에서 호출했던 라이브러리에 의존하며, 이름은 자유롭게 지정해주면 되겠다. 단, 이름이 너무 길면 시각화할 때 모양새가 좋지 않으니 간략하게 명명하는 것이 좋다.

![](/assets/images/posts/143-3.webp)

for문은 전체 모델을 반복 순회하며 res\_cv, res\_train, res\_test에 각각 해당하는 score를 담아준다. 여기서 score는 rmse(root mean squared error)로 지정해 주었으니 낮을수록 좋다.

반복문이 돌면 res\_cv에는 전체 모델의 Cross-Validation Score가, res\_train에는 학습 데이터셋에 대한 예측 Score가, res\_test에는 평가 데이터셋에 대한 예측 Score가 차곡 차곡 쌓일 것이다.

앞서 언급했듯 교차검증은 해당 모델이 얼마나 Robust한가, 즉 이상값(혹은 특이값)에 대한 민감도를 확인하기 위함이다. 많은 모델을 비교 분석함에 있어서 **모델의 복잡도, 예측안정성, 해석가능성 등 다양한 요인을 고려해야 하는데 그 중에서도 가장 중요한 것은 예측안정성**이다. 이미 딥러닝 모델이나 SVM처럼 복잡하고 해석력이 떨어지는 딥러닝 모델도 실무에서 빠지지 않고 활용되고 있는 만큼 안정적인 예측 성능 확보를 우선적으로 고려해야 한다. 교차검증은 이를 간편하게 수행하도록 해준다.

다만, 시계열 분석에 있어서 교차검증은 주의해서 사용할 필요가 있다. 교차검증은 말 그대로 예측 구간을 교차해 가며 성능을 확인하는데, **시계열 데이터의 경우 데이터간 시간적 선후행 관계가 존재하므로 시간지평이 필요한 추세(모멘텀) 분석이나 인과추론 시에는 활용할 수 없다.**

해당 실습의 경우 추세와 계절성을 제거하였으며 (약)정상성을 확보한 시계열에 대한 내재된 패턴을 추정하고자 하므로 교차 검증을 사용하는 것이다. **모델이 패턴을 잘 찾아냈다면 이러한 패턴은 모든 시계열 구간에 걸쳐 통용될 수 있어야 한다.** 다시 말하면, 2010년의 패턴이 2021년에 적용되는 것 뿐 아니라 2021년의 패턴이 2010년에도 적용되는 것이 자연스럽다는 의미다. 단, 여기서 분석 대상이 되는 전체 시계열 데이터는 거시 국면 전환 등으로 잠재 특성이 변하지 않았다는 가정을 전제한다. 

\*위 교차검증 부분에 대한 이해가 어렵다면 그 개념에 대해서는 자료가 넘쳐나니 적극적으로 탐색해보길 바란다. 아래는 추천 자료다.

* [데이터사이언스스쿨 - 교차검증](https://datascienceschool.net/03%20machine%20learning/06.03%20%EA%B5%90%EC%B0%A8%EA%B2%80%EC%A6%9D.html)
* [[Youtube]Machine Learning Fundamentals: Cross Validation](https://www.youtube.com/watch?v=fSytzGwwBVw)

### **2-2. Compare Cross Validation Scores**

2-1의 출력 로그에 이미 결과는 모두 나왔다. 이제 그것을 보기좋게 차트로 구성해보려 한다.

![](/assets/images/posts/143-4.webp)

먼저 models 리스트는 (이름, 모델) 쌍의 튜플로 구성되어 있으므로 list comprehension 문법을 통해 이름만 추출해 x\_labels로 재구조화했다. x\_loc는 차트에 모델 이름이 순서대로 들어갈 수 있도록 하는 좌표값이다.

차트에서 전체 모델을 평균 순으로 정렬할 것이다. 이를 위해 numpy의 argsort() 함수를 사용했으며 그것을 인덱스로 cv score와 모델 이름을 모두 정렬해주었다.

![](/assets/images/posts/143-5.webp)

이렇게 boxplot을 통해 차트를 그려주면 전체 모델의 cv score 분포를 살펴볼 수 있다. cv score가 낮을 수록(좌측) 시계열 데이터 전반에 대한 예측 안정성이 높다. 즉, **Lasso(L1규제), ElasticNet(L1 + L2 규제 혼합)을 포함하는 기본적인 선형 회귀모형들이 cv score가 낮으며, 의사결정(Tree) 모형이나 거리기반(KNN, SVR) 모형 대비 높은 안정성**을 보인다.

참고로 위 차트에서 boxplot 내부의 붉은 선은 중앙값(median)이다. 우리는 앞서 평균으로 정렬했기 때문에 그 순서가 동일하지 않다.

### **2-3. Compare Model Accuray**

앞서 각 모델을 train dataset에 학습시키고, 그렇게 학습된 모델로 train dataset과 test dataset에 대해 각각 예측을 수행했다. 예측 성능은 rmse로 평가했으며, 그것이 낮을 수록 정확도(Accuracy)는 높다.

![](/assets/images/posts/143-6.webp)

차트 시각화를 위한 모델명, 데이터 정렬 방식은 2-2에서 수행한 것과 동일하다. 다만, 이번에는 cv값이 아닌 단일 예측 값이므로 위와 같이 res\_test를 기준으로 정렬해줄 것이다. 즉, test-error가 낮을 수록 차트상 높게 위치하게 된다.

![](/assets/images/posts/143-7.webp)

cv score를 통해서도 확인했지만 lr을 포함해 lasso, elasticnet과 같은 선형 회귀모형이 성능이 가장 좋았으며, 거리기반 모형(SVR, KNN)과 의사결정(Tree) 모형은 반대로 좋지 않았다. 특히 **트리 모형은 앙상블(ExtraTrees)과 함께 Train dataset에 대해 과적합(error=0)**된 것을 확인할 수 있었다.

또한, 신경망 모형의 경우 Train dataset과 Test dataset에서의 예측오차가 가장 균일(두 예측오차간 차이가 적음)했다. 주가수익률예측모델의 경우 이미 학습한 train dataset에 대해서도 예측 성능이 높지 않은 경향을 보이는 점을 고려하면, 신경망 모형이 단순 선형 회귀모형 대비 train dataset에 더 적합되었다고 생각해볼 수 있다. 미미한 수치지만(사실 주가 예측에서 만큼은 결코 미미하지 않다), 너무 복잡한 모형을 단순한 선형 패턴의 데이터를 학습하는 데에 사용했기에 나타난 결과다.

결과적으로, 선형 회귀 모형(lr, lasso, elasticnet)이 상대적으로 좋은 성능을 보인 이유는 2장에서 확인했듯 연관 자산 수익률간의 양의 상관관계, 지연 수익률간의 양의 상관관계가 있었기 때문이다. **지수 추종 ETF 상품에 포함된 대형 연관 자산의 동시적 움직임, 꾸준히 우상향한 애플 주가로 인한 Negative Skew 현상이 이러한 선형 패턴을 형성하는 데에 핵심적인 요소로 작용**했을 것이다.



**관성을 이기는 데이터**

[저작자표시
(새창열림)](https://creativecommons.org/licenses/by/4.0/deed.ko)